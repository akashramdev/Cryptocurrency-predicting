{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Cryptocurrency-predicting finance Recurrent Neural Network**\n\nINTRODUCTION\n\nCreating a recurrent neural network to predict against a time-series dataset, which is going to be cryptocurrency prices.\nThe data we'll be using is Open, High, Low, Close, Volume data for Bitcoin, Ethereum, Litecoin and Bitcoin Cash."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/crypto_data/crypto_data/LTC-USD.csv', names=['time', 'low', 'high', 'open', 'close', 'volume'])\n\nprint(df.head())","execution_count":1,"outputs":[{"output_type":"stream","text":"         time        low     ...          close      volume\n0  1528968660  96.580002     ...      96.580002    9.647200\n1  1528968720  96.449997     ...      96.660004  314.387024\n2  1528968780  96.470001     ...      96.570000   77.129799\n3  1528968840  96.449997     ...      96.500000    7.216067\n4  1528968900  96.279999     ...      96.389999  524.539978\n\n[5 rows x 6 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\n \nmain_df = pd.DataFrame() # begin empty\n\nratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\nfor ratio in ratios:  # begin iteration\n    print(ratio)\n    dataset = f'../input/crypto_data/crypto_data/{ratio}.csv'  # get the full path to the file.\n    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n\n    # rename volume and close to include the ticker so we can still which close/volume is which:\n    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n\n    df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n\n    if len(main_df)==0:  # if the dataframe is empty\n        main_df = df  # then it's just the current df\n    else:  # otherwise, join this data to the main one\n        main_df = main_df.join(df)\n\nmain_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\nmain_df.dropna(inplace=True)\nprint(main_df.head())  # how did we do??\n\nfor c in main_df.columns:\n    print(c)","execution_count":2,"outputs":[{"output_type":"stream","text":"BTC-USD\nLTC-USD\nBCH-USD\nETH-USD\n            BTC-USD_close       ...        ETH-USD_volume\ntime                            ...                      \n1528968720    6487.379883       ...             26.019083\n1528968780    6479.410156       ...              8.449400\n1528968840    6479.410156       ...             26.994646\n1528968900    6479.979980       ...             77.355759\n1528968960    6480.000000       ...              7.503300\n\n[5 rows x 8 columns]\nBTC-USD_close\nBTC-USD_volume\nLTC-USD_close\nLTC-USD_volume\nBCH-USD_close\nBCH-USD_volume\nETH-USD_close\nETH-USD_volume\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\nFUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict? period= minutes\nRATIO_TO_PREDICT = \"LTC-USD\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify(current, future):\n    if float(future) > float(current):\n        return 1\n    else:\n        return 0","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A .shift will just shift the columns for us, a negative shift will shift them \"up.\" So shifting up 3 will give us the price 3 minutes in the future, and we're just assigning this to a new column."},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\nprint(main_df[[f'{RATIO_TO_PREDICT}_close','future']].head())","execution_count":5,"outputs":[{"output_type":"stream","text":"            LTC-USD_close     future\ntime                                \n1528968720      96.660004  96.389999\n1528968780      96.570000  96.519997\n1528968840      96.500000  96.440002\n1528968900      96.389999  96.470001\n1528968960      96.519997  96.400002\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\nprint(main_df[[f'{RATIO_TO_PREDICT}_close','future', 'target']].head(10))","execution_count":6,"outputs":[{"output_type":"stream","text":"            LTC-USD_close     future  target\ntime                                        \n1528968720      96.660004  96.389999       0\n1528968780      96.570000  96.519997       0\n1528968840      96.500000  96.440002       0\n1528968900      96.389999  96.470001       1\n1528968960      96.519997  96.400002       0\n1528969020      96.440002  96.400002       0\n1528969080      96.470001  96.400002       0\n1528969140      96.400002  96.400002       0\n1528969200      96.400002  96.400002       0\n1528969260      96.400002  96.449997       1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Separate out our validation/out of sample data, take the last 5% of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"times = sorted(main_df.index.values)  # get the times\nlast_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]  # get the last 5% of the times\n\nvalidation_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data where the index is in the last 5%\nmain_df = main_df[(main_df.index < last_5pct)]  # now the main_df is all the data up to the last 5%\n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to scale and normalize this data. Create our actual sequences and balance the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \nimport numpy as np\nimport random\nfrom collections import deque\n\ndef preprocess_df(df):\n    df = df.drop(\"future\", 1)  # don't need this anymore.\n\n    for col in df.columns:  # go through all of the columns\n        if col != \"target\":  # normalize all ... except for the target itself!\n            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n            df.dropna(inplace=True)  # remove the nas created by pct_change\n            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n\n    df.dropna(inplace=True)  # cleanup again... jic. \n  \n   # Create our sequences\n    sequential_data = []  # this is a list that will CONTAIN the sequences\n    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n\n    for i in df.values:  # iterate over the values\n        prev_days.append([n for n in i[:-1]])  # store all but the target\n        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n            sequential_data.append([np.array(prev_days), i[-1]])  # append \n\n    random.shuffle(sequential_data)  # shuffle for good measure.\n    \n    # balance the data\n    buys = []  # list that will store our buy sequences and targets\n    sells = []  # list that will store our sell sequences and targets\n\n    for seq, target in sequential_data:  # iterate over the sequential data\n        if target == 0:  # if it's a \"not buy\"\n            sells.append([seq, target])  # append to sells list\n        elif target == 1:  # otherwise if the target is a 1...\n            buys.append([seq, target])  # it's a buy!\n\n    random.shuffle(buys)  # shuffle the buys\n    random.shuffle(sells)  # shuffle the sells!\n\n    lower = min(len(buys), len(sells))  # what's the shorter length?\n\n    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n\n    sequential_data = buys+sells  # add them together\n    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n\n    X = []\n    y = []\n\n    for seq, target in sequential_data:  # going over our new sequential data\n        X.append(seq)  # X is the sequences\n        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n        \n    return np.array(X), y","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, train_y = preprocess_df(main_df)\nvalidation_x, validation_y = preprocess_df(validation_main_df)\n\nprint(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\nprint(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\nprint(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")\n","execution_count":9,"outputs":[{"output_type":"stream","text":"train data: 77922 validation: 3860\nDont buys: 38961, buys: 38961\nVALIDATION Dont buys: 1930, buys: 1930\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Making few more constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nEPOCHS = 10  # how many passes through our data\nBATCH_SIZE = 64  # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\nNAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build the model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import ModelCheckpoint","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n\nmodel.add(CuDNNLSTM(128, return_sequences=True))\nmodel.add(Dropout(0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(CuDNNLSTM(128))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(2, activation='softmax'))","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n\n# Compile model\nmodel.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Checkpoint"},{"metadata":{"trusted":true},"cell_type":"code","source":"#filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n#checkpoint = ModelCheckpoint(\"../input/crypto_data/crypto_data/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model\nhistory = model.fit(\n    train_x, train_y,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=(validation_x, validation_y),\n    #callbacks=[tensorboard, checkpoint],\n)\n","execution_count":23,"outputs":[{"output_type":"stream","text":"Train on 77922 samples, validate on 3860 samples\nEpoch 1/10\n77922/77922 [==============================] - 24s 304us/sample - loss: 0.7244 - acc: 0.5204 - val_loss: 0.6911 - val_acc: 0.5106\nEpoch 2/10\n77922/77922 [==============================] - 23s 292us/sample - loss: 0.6879 - acc: 0.5447 - val_loss: 0.6819 - val_acc: 0.5645\nEpoch 3/10\n77922/77922 [==============================] - 23s 291us/sample - loss: 0.6832 - acc: 0.5602 - val_loss: 0.6850 - val_acc: 0.5578\nEpoch 4/10\n77922/77922 [==============================] - 23s 293us/sample - loss: 0.6815 - acc: 0.5618 - val_loss: 0.6823 - val_acc: 0.5482\nEpoch 5/10\n77922/77922 [==============================] - 22s 289us/sample - loss: 0.6804 - acc: 0.5666 - val_loss: 0.6768 - val_acc: 0.5661\nEpoch 6/10\n77922/77922 [==============================] - 22s 289us/sample - loss: 0.6784 - acc: 0.5682 - val_loss: 0.6794 - val_acc: 0.5741\nEpoch 7/10\n77922/77922 [==============================] - 23s 291us/sample - loss: 0.6768 - acc: 0.5733 - val_loss: 0.6735 - val_acc: 0.5845\nEpoch 8/10\n77922/77922 [==============================] - 22s 286us/sample - loss: 0.6740 - acc: 0.5782 - val_loss: 0.6761 - val_acc: 0.5808\nEpoch 9/10\n77922/77922 [==============================] - 22s 287us/sample - loss: 0.6706 - acc: 0.5872 - val_loss: 0.6815 - val_acc: 0.5614\nEpoch 10/10\n77922/77922 [==============================] - 22s 288us/sample - loss: 0.6644 - acc: 0.5977 - val_loss: 0.6853 - val_acc: 0.5744\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"This is for LTC-USD. Run the same model again for different cryptocurrency and compare "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score model\nscore = model.evaluate(validation_x, validation_y, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\n\nmodel.save(\"RNN_Final\")\n","execution_count":24,"outputs":[{"output_type":"stream","text":"Test loss: 0.6852892930025881\nTest accuracy: 0.5743523\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}